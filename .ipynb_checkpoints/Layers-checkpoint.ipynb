{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Convolution:\n",
    "    #include init? idk\n",
    "        \n",
    "    # Given set of filters (features), iterate over input and multiply\n",
    "    # img_in: a NxM matrix representing one of the RGB values of the input\n",
    "    # features: filters/features that we compare the input against\n",
    "    # step_size: fixed to 1 (does not have any effect)\n",
    "    # returns a PxQ matrix (P<N, Q<M) where each value is the result of multiplying\n",
    "    # filter with the input, then dividing by the size of the filter\n",
    "    def forward_prop(self, img_in, features, step_size):\n",
    "        N = len(img_in)\n",
    "        M = len(img_in[0])\n",
    "        # if step size doesn't match up -> padding()\n",
    "        \n",
    "        # gives us amount of padding needed\n",
    "        pad_N = (len(features) - 1) / 2\n",
    "        pad_M = (len(features[0]) - 1) / 2\n",
    "        \n",
    "        if (pad_N is not 0) or (pad_M is not 0):\n",
    "            img_in = self.padding(img_in, N+pad_N, M+pad_M) #padded img\n",
    "        print(img_in)\n",
    "        # should be whole numbers\n",
    "        P = ((len(img_in) - len(features)) / step_size) + 1\n",
    "        Q = ((len(img_in[0]) - len(features)) / step_size) + 1\n",
    "        \n",
    "        # find good ways to add padding, possibly this part is not needed?\n",
    "        if P.is_integer() is False:\n",
    "            return \"Bad Dimension P\"\n",
    "        if Q.is_integer() is False:\n",
    "            return \"Bad dimension Q\"\n",
    "        else:\n",
    "            P = int(P)\n",
    "            Q = int(Q)\n",
    "            \n",
    "        print(P, Q)\n",
    "        out = np.zeros((P, Q)) # PxQ output array\n",
    "        \n",
    "        # iterate thru the input and output to corresponding part in out\n",
    "        for i in range(0, P):\n",
    "            for j in range (0, Q):\n",
    "                # Take dot product of the flattened filter and part of input it is covering\n",
    "                out[i, j] = np.dot(np.ndarray.flatten(img_in[i:i+len(features),\n",
    "                            j:j+len(features[0])]), np.ndarray.flatten(features))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    # loss = loss gradient from the next layer (feeding back to previous layer)\n",
    "    # features = previous/original kernel/filter\n",
    "    # learning_rate = alpha or how much change we want (the same across the network)\n",
    "    def back_prop(self, img_in, loss, features, learning_rate):\n",
    "        dL_dF = np.zeros(np.shape(features))\n",
    "        X = img_in\n",
    "        N = len(X)\n",
    "        M = len(X[0])\n",
    "        # update filter\n",
    "        # X is the image @ this stage\n",
    "        # chain rule: dL_dF = dL_dO * dO_dF\n",
    "        # but dL_dO is the input loss\n",
    "        # and dO_dF results in the image X\n",
    "        # dL_dF = convolution 2d between X (image @ this stage) and loss   \n",
    "        # ex. dL_dF 2x2 =  Conv image 3x3 , loss 2x2\n",
    "        for i in range(0, N):\n",
    "            for j in range (0, M):\n",
    "                print(np.ndarray.flatten(X[i:i+len(loss),\n",
    "                            j:j+len(loss[0])]))\n",
    "                print(np.ndarray.flatten(loss))\n",
    "                dL_dF[i, j] = np.dot(np.ndarray.flatten(X[i:i+len(loss),\n",
    "                            j:j+len(loss[0])]), np.ndarray.flatten(loss))\n",
    "\n",
    "        # update the image X\n",
    "        # need to pad the filter and rotate it 180deg\n",
    "        # convolution from right to left and bottom to top\n",
    "        # F22 F21\n",
    "        # F12 F11\n",
    "        # dL_dX = convolution 2d between rot180(Filter) and loss \n",
    "        \n",
    "#         dL_dX = np.zeros(np.shape())\n",
    "        \n",
    "        # F = F - a * dL/dF\n",
    "        features = features - learning_rate * dL_dF\n",
    "\n",
    "        return features, X\n",
    "    \n",
    "    # Add 0s to the N and M sides of the input as needed\n",
    "    def padding(self, orig_img, N, M):\n",
    "        starting_row = int((N - orig_img.shape[0]) / 2)\n",
    "        starting_column = int((M - orig_img.shape[1]) / 2)\n",
    "        pad_arr = np.zeros((N, M))\n",
    "        pad_arr[starting_row:starting_row+orig_img.shape[0], starting_column:starting_column+orig_img.shape[1]] = orig_img\n",
    "        return pad_arr\n",
    "    \n",
    "# Can implement either max or avg pooling, going w max for now\n",
    "class Pooling: \n",
    "    # Go thru sections of the original matrix and only take the highest value\n",
    "    # Put this into a new PxQ matrix\n",
    "    # Pool dim is a single int representing both size of the 'pool filter' and\n",
    "    # the stride. Ex: 2 -> 2x2 pooling with stride 2\n",
    "    def forward_prop(self, img_in, pool_dim):\n",
    "        # if step size doesn't match up -> padding()  \n",
    "        # gives us amount of padding needed\n",
    "        pad_N = (len(img_in) - pool_dim) % pool_dim\n",
    "        pad_M = (len(img_in[0]) - pool_dim) % pool_dim\n",
    "        \n",
    "        if (pad_N is not 0) or (pad_M is not 0):\n",
    "            img_in = self.padding(img_in, len(img_in)+pad_N, len(img_in[0])+pad_M)\n",
    "        \n",
    "        # reduce by a factor of whatever stride is\n",
    "        P = int(len(img_in) / pool_dim)\n",
    "        Q = int(len(img_in[0]) / pool_dim)\n",
    "        out = np.zeros((P, Q))\n",
    "        # loop thru input matrix\n",
    "        for i in range(0, P):\n",
    "            for j in range(0, Q):\n",
    "                # get largest value in pool\n",
    "                vert = i * pool_dim\n",
    "                horiz = j * pool_dim\n",
    "                pool = img_in[vert:vert+pool_dim, horiz:horiz+pool_dim]\n",
    "                #print(pool)\n",
    "                out[i,j] = np.amax(pool)\n",
    "    \n",
    "        return out\n",
    "    \n",
    "    def back_prop(self):\n",
    "        \n",
    "        return None\n",
    "    def padding(self, orig_img, N, M):\n",
    "        starting_row = int((N - orig_img.shape[0]) / 2)\n",
    "        starting_column = int((M - orig_img.shape[1]) / 2)\n",
    "        pad_arr = np.zeros((N, M))\n",
    "        pad_arr[starting_row:starting_row+orig_img.shape[0], starting_column:starting_column+orig_img.shape[1]] = orig_img\n",
    "        return pad_arr\n",
    "    \n",
    "class ReLU():\n",
    "    def forward_prop(self, img_in):\n",
    "        for i in range(0, len(img_in)):\n",
    "            for j in range(0, len(img_in[0])):\n",
    "                if img_in[i, j] < 0:\n",
    "                    img_in[i, j] = 0\n",
    "        return img_in\n",
    "    def back_prop():\n",
    "        return None\n",
    "    \n",
    "class Sigmoid_Act():\n",
    "    def forward_prop():\n",
    "        return None\n",
    "    def back_prop():\n",
    "        return None\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  5  2  7]\n",
      " [ 5  5  5  0]\n",
      " [ 5  5  5 22]\n",
      " [ 1  2  3  4]]\n",
      "2 2\n",
      "[[25.  6.]\n",
      " [23. 40.]]\n",
      "[[5. 5.]\n",
      " [5. 6.]]\n",
      "[[5 0 0]\n",
      " [0 6 2]\n",
      " [5 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# tests\n",
    "def test_conv_forward():\n",
    "    test_arr = np.array(([5, 5, 2, 7],\n",
    "                         [5, 5, 5, 0],\n",
    "                         [5, 5, 5, 22],\n",
    "                         [1, 2, 3, 4]))\n",
    "    feat_arr = np.array(([2, -1, 0], \n",
    "                         [2, 1, 1],\n",
    "                         [1, 0, -1]))\n",
    "    step = 1\n",
    "    conv_layer = Convolution()\n",
    "    print(conv_layer.forward_prop(test_arr, feat_arr, step))\n",
    "    \n",
    "def test_pool_forward():\n",
    "    test_arr = np.array(([5, 5, 2],\n",
    "                         [5, 6, 2],\n",
    "                         [5, 5, 4]))\n",
    "    pool_dim = 2\n",
    "    pool_layer = Pooling()\n",
    "    print(pool_layer.forward_prop(test_arr, pool_dim))\n",
    "    \n",
    "def test_ReLU():\n",
    "    test_arr = np.array(([5, -1, -1],\n",
    "                         [-4, 6, 2],\n",
    "                         [5, 0, -3333]))\n",
    "    ReLU_layer = ReLU()\n",
    "    print(ReLU_layer.forward_prop(test_arr))\n",
    "    \n",
    "    \n",
    "test_conv_forward()\n",
    "test_pool_forward()\n",
    "test_ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  5.  2.  7.  0.]\n",
      " [ 0.  5.  5.  5.  0.  0.]\n",
      " [ 0.  5.  5.  5. 22.  0.]\n",
      " [ 0.  1.  2.  3.  4.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  5.  2.  7.  0.  0.]\n",
      " [ 0.  0.  5.  5.  5.  0.  0.  0.]\n",
      " [ 0.  0.  5.  5.  5. 22.  0.  0.]\n",
      " [ 0.  0.  1.  2.  3.  4.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "[5 5 5 5]\n",
      "[1 2 3 4]\n",
      "[5 2 5 5]\n",
      "[1 2 3 4]\n",
      "[2 7 5 0]\n",
      "[1 2 3 4]\n",
      "[7 0]\n",
      "[1 2 3 4]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (2,) and (4,) not aligned: 2 (dim 0) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-473462f35194>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mtest_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mtest_conv_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-58-473462f35194>\u001b[0m in \u001b[0;36mtest_conv_backward\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m                      [3, 4]))\n\u001b[0;32m     27\u001b[0m     \u001b[0mconv_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mtest_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-4bf15bd179bf>\u001b[0m in \u001b[0;36mback_prop\u001b[1;34m(self, img_in, loss, features, learning_rate)\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 dL_dF[i, j] = np.dot(np.ndarray.flatten(X[i:i+len(loss),\n\u001b[1;32m---> 69\u001b[1;33m                             j:j+len(loss[0])]), np.ndarray.flatten(loss))\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;31m# update the image X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,) and (4,) not aligned: 2 (dim 0) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "# tests 2\n",
    "# def padding(self, orig_img, N, M)\n",
    "def test_padding():\n",
    "    conv_layer = Convolution()\n",
    "    test_arr = np.array(([5, 5, 2, 7],\n",
    "                         [5, 5, 5, 0],\n",
    "                         [5, 5, 5, 22],\n",
    "                         [1, 2, 3, 4]))\n",
    "    print(conv_layer.padding(test_arr,6,6))\n",
    "    test_arr = np.array(([5, 5, 2, 7],\n",
    "                         [5, 5, 5, 0],\n",
    "                         [5, 5, 5, 22],\n",
    "                         [1, 2, 3, 4]))\n",
    "    print(conv_layer.padding(test_arr,8,8))\n",
    "\n",
    "# def back_prop(self, img_in, loss, features, learning_rate)\n",
    "def test_conv_backward():\n",
    "    test_arr = np.array(([5, 5, 2, 7],\n",
    "                         [5, 5, 5, 0],\n",
    "                         [5, 5, 5, 22],\n",
    "                         [1, 2, 3, 4]))\n",
    "    feat_arr = np.array(([2, -1, 0], \n",
    "                         [2, 1, 1],\n",
    "                         [1, 0, -1]))\n",
    "    loss = np.array(([1, 2], \n",
    "                     [3, 4]))\n",
    "    conv_layer = Convolution()\n",
    "    print(conv_layer.back_prop(test_arr, loss, feat_arr, 0.01))\n",
    "    \n",
    "test_padding()\n",
    "test_conv_backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
