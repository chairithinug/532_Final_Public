{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Convolution:\n",
    "    #include init? idk\n",
    "        \n",
    "    # Given set of filters (features) #odd x #odd, iterate over input and multiply\n",
    "    # img_in: a square NxM #even x #even matrix representing one of the RGB values of the input\n",
    "    # features: filters/features that we compare the input against\n",
    "    # step_size: fixed to 1 (does not have any effect)\n",
    "    # returns a NxM matrix where each value is the result of multiplying\n",
    "    # filter with the input, then dividing by the size of the filter\n",
    "    def forward_prop(self, img_in, features):\n",
    "        N = len(img_in)\n",
    "        M = len(img_in[0])\n",
    "        # if step size doesn't match up -> padding()\n",
    "        \n",
    "        # gives us amount of padding needed\n",
    "        pad_N = (len(features) - 1)\n",
    "        pad_M = (len(features[0]) - 1)\n",
    "        \n",
    "        # padded img\n",
    "        img_in = self.padding(img_in, N + pad_N, M + pad_M)\n",
    "        # print(img_in)\n",
    "        \n",
    "        # NxM output array (square)\n",
    "        out = np.zeros((N, M))\n",
    "        \n",
    "        # iterate thru the input and output to corresponding part in out\n",
    "        for i in range(0, N):\n",
    "            for j in range (0, M):\n",
    "                # Take dot product of the flattened filter and part of input it is covering\n",
    "                out[i, j] = np.dot(np.ndarray.flatten(img_in[i:i+len(features),\n",
    "                            j:j+len(features[0])]), np.ndarray.flatten(features))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    # assume stride = 1 (not tested for stride > 1)\n",
    "    # loss = loss gradient from the next layer (feeding back to previous layer)\n",
    "    # filter_weight = previous/original kernel/filter\n",
    "    # learning_rate = alpha or how much change we want (the same across the network)\n",
    "    # loss_size = img_size\n",
    "    def back_prop(self, img_in, loss, filter_weight, learning_rate):\n",
    "        dL_dF = np.zeros(np.shape(filter_weight))\n",
    "        X = img_in\n",
    "        N = len(X)\n",
    "        M = len(X[0])\n",
    "        \n",
    "        pad_N = (len(filter_weight) - 1)\n",
    "        pad_M = (len(filter_weight[0]) - 1)\n",
    "\n",
    "        # padded img\n",
    "        X = self.padding(X, N + pad_N, M + pad_M)\n",
    "        print(\"padded img\", X)\n",
    "        \n",
    "        # update filter\n",
    "        # X is the image @ this stage\n",
    "        # chain rule: dL_dF = dL_dO * dO_dF\n",
    "        # but dL_dO is the input loss\n",
    "        # and dO_dF results in the image X\n",
    "        # dL_dF = convolution 2d between X (image @ this stage) and loss   \n",
    "        # ex. dL_dF 3x3 =  Conv image 4x4 (padded to 6x6), loss 4x4\n",
    "        for i in range(0, N - 1):\n",
    "            for j in range (0, M - 1):\n",
    "                print(np.ndarray.flatten(X[i:i+len(loss), j:j+len(loss[0])]))\n",
    "                dL_dF[i, j] = np.dot(np.ndarray.flatten(X[i:i+len(loss),\n",
    "                            j:j+len(loss[0])]), np.ndarray.flatten(loss))\n",
    "        print(\"dL_dF\")\n",
    "        print(dL_dF)\n",
    "        \n",
    "        \n",
    "        # update the image X\n",
    "        # need to rotate the filter 180deg and pad it\n",
    "        # convolution from right to left and bottom to top\n",
    "        # F33 F32 F31\n",
    "        # F23 F22 F21\n",
    "        # F13 F12 F11\n",
    "        dL_dX = np.zeros(np.shape(X))\n",
    "        # rotate the filter 180deg\n",
    "        rot_filter_weight = np.rot90(filter_weight, 2)\n",
    "        # pad the filter \n",
    "        loss = self.padding(loss, N + pad_N, M + pad_M)\n",
    "        print(\"padded loss\")\n",
    "        print(loss)\n",
    "        # dL_dX = convolution 2d between rot180(Filter) and loss \n",
    "        # convolution from right to left and bottom to top\n",
    "        for i in range(N - 1, -1, -1):\n",
    "            for j in range (M - 1, -1, -1):\n",
    "                #print(i,j)\n",
    "                #print(np.ndarray.flatten(loss[i:i+len(rot_filter_weight), j:j+len(rot_filter_weight[0])]))\n",
    "                dL_dX[i, j] = np.dot(np.ndarray.flatten(loss[i:i+len(rot_filter_weight),\n",
    "                            j:j+len(rot_filter_weight[0])]), np.ndarray.flatten(rot_filter_weight))\n",
    "        \n",
    "        print(\"dL_dX\")\n",
    "        print(dL_dX)\n",
    "        # F = F - a * dL/dF\n",
    "        filter_weight = filter_weight - learning_rate * dL_dF\n",
    "        print(\"updated_features\")\n",
    "        print(filter_weight)\n",
    "        return filter_weight, X\n",
    "    \n",
    "    # Add 0s to the border of orig_img as needed to achieve NxM matrix\n",
    "    # assume orig_img is a square matrix with #odd x #odd\n",
    "    def padding(self, orig_img, N, M):\n",
    "        starting_row = (N - orig_img.shape[0]) // 2\n",
    "        starting_column = (M - orig_img.shape[1]) // 2\n",
    "        pad_arr = np.zeros((N, M))\n",
    "        pad_arr[starting_row:starting_row+orig_img.shape[0], starting_column:starting_column+orig_img.shape[1]] = orig_img\n",
    "        return pad_arr\n",
    "    \n",
    "# Can implement either max or avg pooling, going w max for now\n",
    "class Pooling: \n",
    "    # Go thru sections of the original matrix and only take the highest value\n",
    "    # Put this into a new PxQ matrix\n",
    "    # Pool dim is a single int representing both size of the 'pool filter' and\n",
    "    # the stride. Ex: 2 -> 2x2 pooling with stride 2\n",
    "    def forward_prop(self, img_in, pool_dim):\n",
    "        # if step size doesn't match up -> padding()  \n",
    "        # gives us amount of padding needed\n",
    "        pad_N = (len(img_in) - pool_dim) % pool_dim\n",
    "        pad_M = (len(img_in[0]) - pool_dim) % pool_dim\n",
    "        \n",
    "        if (pad_N is not 0) or (pad_M is not 0):\n",
    "            img_in = self.padding(img_in, len(img_in)+pad_N, len(img_in[0])+pad_M)\n",
    "        \n",
    "        # reduce by a factor of whatever stride is\n",
    "        P = int(len(img_in) / pool_dim)\n",
    "        Q = int(len(img_in[0]) / pool_dim)\n",
    "        out = np.zeros((P, Q))\n",
    "        # loop thru input matrix\n",
    "        for i in range(0, P):\n",
    "            for j in range(0, Q):\n",
    "                # get largest value in pool\n",
    "                vert = i * pool_dim\n",
    "                horiz = j * pool_dim\n",
    "                pool = img_in[vert:vert+pool_dim, horiz:horiz+pool_dim]\n",
    "                #print(pool)\n",
    "                out[i,j] = np.amax(pool)\n",
    "    \n",
    "        return out\n",
    "    \n",
    "    def back_prop(self):\n",
    "        \n",
    "        return None\n",
    "    def padding(self, orig_img, N, M):\n",
    "        starting_row = int((N - orig_img.shape[0]) // 2)\n",
    "        starting_column = int((M - orig_img.shape[1]) // 2)\n",
    "        pad_arr = np.zeros((N, M))\n",
    "        pad_arr[starting_row:starting_row+orig_img.shape[0], starting_column:starting_column+orig_img.shape[1]] = orig_img\n",
    "        return pad_arr\n",
    "    \n",
    "class ReLU():\n",
    "    def forward_prop(self, img_in):\n",
    "        for i in range(0, len(img_in)):\n",
    "            for j in range(0, len(img_in[0])):\n",
    "                if img_in[i, j] < 0:\n",
    "                    img_in[i, j] = 0\n",
    "        return img_in\n",
    "    def back_prop():\n",
    "        return None\n",
    "    \n",
    "class Sigmoid_Act():\n",
    "    def forward_prop():\n",
    "        return None\n",
    "    def back_prop():\n",
    "        return None\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5. 17. 24. 16.]\n",
      " [ 0. 25.  6. 12.]\n",
      " [ 3. 23. 40. 45.]\n",
      " [-2. 12. 16. -2.]]\n",
      "[[6. 2.]\n",
      " [5. 4.]]\n",
      "[[5 0 0]\n",
      " [0 6 2]\n",
      " [5 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# tests\n",
    "def test_conv_forward():\n",
    "    test_arr = np.array(([5, 5, 2, 7],\n",
    "                         [5, 5, 5, 0],\n",
    "                         [5, 5, 5, 22],\n",
    "                         [1, 2, 3, 4]))\n",
    "    feat_arr = np.array(([2, -1, 0], \n",
    "                         [2, 1, 1],\n",
    "                         [1, 0, -1]))\n",
    "    conv_layer = Convolution()\n",
    "    print(conv_layer.forward_prop(test_arr, feat_arr))\n",
    "    \n",
    "def test_pool_forward():\n",
    "    test_arr = np.array(([5, 5, 2],\n",
    "                         [5, 6, 2],\n",
    "                         [5, 5, 4]))\n",
    "    pool_dim = 2\n",
    "    pool_layer = Pooling()\n",
    "    print(pool_layer.forward_prop(test_arr, pool_dim))\n",
    "    \n",
    "def test_ReLU():\n",
    "    test_arr = np.array(([5, -1, -1],\n",
    "                         [-4, 6, 2],\n",
    "                         [5, 0, -3333]))\n",
    "    ReLU_layer = ReLU()\n",
    "    print(ReLU_layer.forward_prop(test_arr))\n",
    "    \n",
    "    \n",
    "test_conv_forward()\n",
    "test_pool_forward()\n",
    "test_ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: padding\n",
      "[[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  5.  2.  7.  0.]\n",
      " [ 0.  5.  5.  5.  0.  0.]\n",
      " [ 0.  5.  5.  5. 22.  0.]\n",
      " [ 0.  1.  2.  3.  4.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  5.  2.  7.  0.  0.]\n",
      " [ 0.  0.  5.  5.  5.  0.  0.  0.]\n",
      " [ 0.  0.  5.  5.  5. 22.  0.  0.]\n",
      " [ 0.  0.  1.  2.  3.  4.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 2. 3. 0.]\n",
      " [0. 4. 5. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# tests 2\n",
    "# def padding(self, orig_img, N, M)\n",
    "def test_padding():\n",
    "    conv_layer = Convolution()\n",
    "    test_arr = np.array(([5, 5, 2, 7],\n",
    "                         [5, 5, 5, 0],\n",
    "                         [5, 5, 5, 22],\n",
    "                         [1, 2, 3, 4]))\n",
    "    print(conv_layer.padding(test_arr,6,6))\n",
    "    test_arr = np.array(([5, 5, 2, 7],\n",
    "                         [5, 5, 5, 0],\n",
    "                         [5, 5, 5, 22],\n",
    "                         [1, 2, 3, 4]))\n",
    "    print(conv_layer.padding(test_arr,8,8))\n",
    "    test_arr = np.array(([2, 3],\n",
    "                         [4, 5]))\n",
    "    print(conv_layer.padding(test_arr,4,4))\n",
    "    \n",
    "print(\"TEST: padding\")\n",
    "test_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: back_prop\n",
      "padded img [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  5.  2.  7.  0.]\n",
      " [ 0.  5.  5.  5.  0.  0.]\n",
      " [ 0.  5.  5.  5. 22.  0.]\n",
      " [ 0.  4.  3.  2.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "[0. 0. 0. 0. 0. 5. 5. 2. 0. 5. 5. 5. 0. 5. 5. 5.]\n",
      "[ 0.  0.  0.  0.  5.  5.  2.  7.  5.  5.  5.  0.  5.  5.  5. 22.]\n",
      "[ 0.  0.  0.  0.  5.  2.  7.  0.  5.  5.  0.  0.  5.  5. 22.  0.]\n",
      "[0. 5. 5. 2. 0. 5. 5. 5. 0. 5. 5. 5. 0. 4. 3. 2.]\n",
      "[ 5.  5.  2.  7.  5.  5.  5.  0.  5.  5.  5. 22.  4.  3.  2.  1.]\n",
      "[ 5.  2.  7.  0.  5.  5.  0.  0.  5.  5. 22.  0.  3.  2.  1.  0.]\n",
      "[0. 5. 5. 5. 0. 5. 5. 5. 0. 4. 3. 2. 0. 0. 0. 0.]\n",
      "[ 5.  5.  5.  0.  5.  5.  5. 22.  4.  3.  2.  1.  0.  0.  0.  0.]\n",
      "[ 5.  5.  0.  0.  5.  5. 22.  0.  3.  2.  1.  0.  0.  0.  0.  0.]\n",
      "dL_dF\n",
      "[[ 48.  22.  59.]\n",
      " [103. 184. 248.]\n",
      " [147. 147. 248.]]\n",
      "padded loss\n",
      "[[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  3.  1.  9.  0.]\n",
      " [ 0.  2.  4.  6. -1.  0.]\n",
      " [ 0.  9.  7.  5. -3.  0.]\n",
      " [ 0. -1. -2. -3. -4.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "dL_dX\n",
      "[[ 17.  18.  14.  11.   0.   0.]\n",
      " [ 18.  17.   3.   7.   0.   0.]\n",
      " [ 24.  26.  -4.   0.   0.   0.]\n",
      " [  2. -13. -23. -12.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n",
      "updated_features\n",
      "[[ 1.52 -1.22 -0.59]\n",
      " [ 0.97 -0.84 -1.48]\n",
      " [-0.47 -1.47 -3.48]]\n"
     ]
    }
   ],
   "source": [
    "# tests 3\n",
    "# def back_prop(self, img_in, loss, features, learning_rate)\n",
    "def test_conv_backward():\n",
    "    test_arr = np.array(([5, 5, 2, 7],\n",
    "                         [5, 5, 5, 0],\n",
    "                         [5, 5, 5, 22],\n",
    "                         [4, 3, 2, 1]))\n",
    "    feat_arr = np.array(([2, -1, 0], \n",
    "                         [2, 1, 1],\n",
    "                         [1, 0, -1]))\n",
    "    loss = np.array(([5, 3, 1, 9], \n",
    "                     [2, 4, 6, -1],\n",
    "                     [9, 7, 5, -3],\n",
    "                     [-1,-2,-3,-4]))\n",
    "    conv_layer = Convolution()\n",
    "    conv_layer.back_prop(test_arr, loss, feat_arr, 0.01)\n",
    "    \n",
    "print(\"TEST: back_prop\")\n",
    "test_conv_backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
